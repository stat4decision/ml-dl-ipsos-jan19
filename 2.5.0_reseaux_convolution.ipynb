{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2.5.0_reseaux_convolution.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "3DV2aXrswKZM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "e2aad530-979e-44ff-8f7a-3cd1bb9885f4"
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "keras.__version__"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.2.4'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "metadata": {
        "id": "yWdAmdvfwKZT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Les réseaux à convolutions\n",
        "\n",
        "Ces réseaux de neurones comprennent deux nouvelles types de couches :\n",
        "    \n",
        "- les couches de convolutions\n",
        "- les couches de pooling"
      ]
    },
    {
      "metadata": {
        "id": "WlPC24lJwKZV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "- Bien qu'efficaces pour le traitement d'images, les perceptrons multicouches (MLP) ont des difficultés à gérer des images de grande taille, dû à la croissance exponentielle du nombre de connexions avec la taille de l'image\n",
        "\n",
        "\n",
        "- Les réseaux de neurones convolutifs, limitent au contraire le nombre de connexions entre un neurone et les neurones des couches adjacentes, ce qui diminue drastiquement le nombre de paramètres à apprendre"
      ]
    },
    {
      "metadata": {
        "id": "9G8BX4XUwKZW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "http://scs.ryerson.ca/~aharley/vis/conv/flat.html"
      ]
    },
    {
      "metadata": {
        "id": "F3D37v7BwKZX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Les couches de convolution\n",
        "\n",
        "La différence fondamentale entre une couche densément connectée et une couche de convolution est la suivante: \n",
        "\n",
        "- les couches denses apprennent des motifs globaux dans leur espace de fonctions en entrée (par exemple, pour un chiffre MNIST, des motifs impliquant tous les pixels), tandis que les couches de convolution apprennent des motifs locaux.\n",
        "\n",
        "Dans le cas des images, des motifs trouvés dans de petites fenêtres 2D des entrées. \n",
        "\n",
        "![image](https://github.com/stat4decision/ml-dl-ipsos-jan19/blob/master/images/conv.jpg?raw=1)"
      ]
    },
    {
      "metadata": {
        "id": "HuoMiU3LwKZY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "Cette caractéristique clé confère à convnets deux propriétés intéressantes:\n",
        "\n",
        "- Les modèles qu’ils apprennent sont des invariants de traduction.\n",
        "\n",
        "- Ils peuvent apprendre les hiérarchies spatiales des modèles"
      ]
    },
    {
      "metadata": {
        "id": "kKzN3uoSwKZa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Les convolutions sont définies par deux paramètres clés:\n",
        "\n",
        "- Taille des patchs extraits des entrées\n",
        "\n",
        "- Profondeur de la carte de caractéristiques en sortie\n",
        "\n",
        "![image](https://github.com/stat4decision/ml-dl-ipsos-jan19/blob/master/images/conv2.jpg?raw=1)"
      ]
    },
    {
      "metadata": {
        "id": "Mh5SS_UVwKZb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "La couche de convolution est la composante clé des réseaux de neurones convolutifs, et constitue toujours au moins leur première couche.\n",
        "\n",
        "Son but est de repérer la présence d'un ensemble de features dans les images reçues en entrée. Pour cela, on réalise un filtrage par convolution : le principe est de faire \"glisser\" une fenêtre représentant la feature sur l'image, et de calculer le produit de convolution entre la feature et chaque portion de l'image balayée. Une feature est alors vue comme un filtre : les deux termes sont équivalents dans ce contexte. \n",
        "\n",
        "La couche de convolution reçoit donc en entrée plusieurs images, et calcule la convolution de chacune d'entre elles avec chaque filtre. Les filtres correspondent exactement aux features que l'on souhaite retrouver dans les images. \n",
        "\n",
        "On obtient pour chaque paire (image, filtre) une carte d'activation, ou feature map, qui nous indique où se situent les features dans l'image : plus la valeur est élevée, plus l'endroit correspondant dans l'image ressemble à la feature. \n",
        "\n",
        "## Comment choisir les features ?\n",
        "\n",
        "Contrairement aux méthodes traditionnelles, les features ne sont pas pré-définies selon un formalisme particulier, mais apprises par le réseau lors la phase d'entraînement ! Les noyaux des filtres désignent les poids de la couche de convolution. Ils sont initialisés puis mis à jour par rétropropagation du gradient. "
      ]
    },
    {
      "metadata": {
        "id": "N6SJTEfgwKZc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Les couches de pooling\n",
        "\n",
        "Chaque couche MaxPooling2D permet de réduire la taille des cartes de caractéristiaues. \n",
        "\n",
        "Ce type de couche est souvent placé entre deux couches de convolution : elle reçoit en entrée plusieurs feature maps, et applique à chacune d'entre elles l'opération de pooling. \n",
        "\n",
        "L'opération de pooling consiste à réduire la taille des images, tout en préservant leurs caractéristiques importantes.\n",
        "\n",
        "\n",
        "C’est le rôle du pooling : sous-échantillonner de manière agressive les cartes de features."
      ]
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "yXghWN_ewKZd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Un cas concret\n",
        "\n",
        "Nous allons utiliser notre réseau convnet pour classer les chiffres MNIST.\n",
        "\n",
        "Les 6 lignes de code ci-dessous vous montrent à quoi ressemble un convnet de base. \n",
        "\n",
        "\n",
        "C'est une pile de couches `Conv2D` et` MaxPooling2D`\n",
        "\n",
        "\n",
        "Il est important de noter qu'un convnet prend en entrée des tenseurs de la forme `(image_height, image_width, image_channels)` \n",
        "\n",
        "\n",
        "Dans notre cas, nous allons configurer notre convnet pour traiter des entrées de taille `(28, 28, 1)`, qui est le format des images MNIST. \n",
        "\n",
        "\n",
        "Nous faisons cela via l'argument `input_shape = (28, 28, 1)`"
      ]
    },
    {
      "metadata": {
        "id": "dXCpVtPUwKZf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras import layers\n",
        "from keras import models\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7lGn5chGwKZh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Voici son architecture :"
      ]
    },
    {
      "metadata": {
        "id": "OpMBAqngwKZi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        },
        "outputId": "7230e59b-7132-4ae4-af19-b97e1afe97ee"
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 11, 11, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 64)          0         \n",
            "=================================================================\n",
            "Total params: 18,816\n",
            "Trainable params: 18,816\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "LH8S-hYXwKZm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Vous pouvez voir que la sortie de chaque couche `Conv2D` et` MaxPooling2D` est un tenseur 3D de forme `(hauteur, largeur, canaux)`. \n",
        "\n",
        "\n",
        "Les dimensions en largeur et en hauteur ont tendance à diminuer à mesure que nous progressons dans le réseau. Le nombre de canaux est contrôlé par le premier argument passé aux couches `Conv2D` (par exemple 32 ou 64).\n",
        "\n",
        "\n",
        "Nous devons donc aplatir nos sorties 3D sur 1D, puis ajouter quelques couches `Dense` au-dessus:"
      ]
    },
    {
      "metadata": {
        "id": "RsEEGetjwKZo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(10, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "81dHtgczwKZr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "outputId": "e1679a66-72cc-4715-f72a-40d0d0f20f05"
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 11, 11, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 1600)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                102464    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 121,930\n",
            "Trainable params: 121,930\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "R1YrOD91wKZv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Maintenant, entraînons notre réseau sur les chiffres du MNIST"
      ]
    },
    {
      "metadata": {
        "id": "-8ES38AuwKZw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "74fe577f-8e30-40a6-9f58-1665d4dddee2"
      },
      "cell_type": "code",
      "source": [
        "from keras.datasets import mnist\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "train_images = train_images.reshape((60000, 28, 28, 1))\n",
        "train_images = train_images.astype('float32') / 255\n",
        "\n",
        "test_images = test_images.reshape((10000, 28, 28, 1))\n",
        "test_images = test_images.astype('float32') / 255\n",
        "\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IZistIWIwKZz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "5ee6ac4e-e2a7-4af7-cd0a-77344e5ec9b5"
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.fit(train_images, train_labels, epochs=5, batch_size=64)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 11s 187us/step - loss: 0.1699 - acc: 0.9479\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 8s 127us/step - loss: 0.0503 - acc: 0.9848\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 8s 128us/step - loss: 0.0351 - acc: 0.9895\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 8s 128us/step - loss: 0.0266 - acc: 0.9919\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 8s 127us/step - loss: 0.0210 - acc: 0.9939\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f149d665ef0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "Yj9q2yKawKZ3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4722c13d-c98a-4e74-9d14-8c9bc31baff1"
      },
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(test_images, test_labels)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 87us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "04K2DOkZwKZ7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6ecd9fc5-54fd-4394-88fe-41818ad00017"
      },
      "cell_type": "code",
      "source": [
        "test_acc"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9909"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "iKMekZLBwKZ_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Le paramétrage des couches\n",
        "\n",
        "Les couches de convolution et de pooling possèdent des hyperparamètres. \n",
        "\n",
        "\n",
        "La taille des feature maps en sortie des couches de convolution et de pooling dépend des hyperparamètres.\n",
        "\n",
        "\n",
        "Chaque image (ou feature map) est de dimensions W×H×D, où W est sa largeur en pixels, H sa hauteur en pixels et D (1 ou 3).\n",
        "\n",
        "La couche de convolution possède quatre hyperparamètres :\n",
        "- Le nombre de filtres K\n",
        "- La taille F des filtres : chaque filtre est de dimensions F×F×D pixels. \n",
        "- Le pas S avec lequel on fait glisser la fenêtre correspondant au filtre sur l'image.\n",
        "- Le zero-padding  P : on ajoute à l'image en entrée de la couche un contour noir d'épaisseur P pixels. \n",
        "\n",
        "La couche de pooling présente seulement deux hyperparamètres :\n",
        "- La taille F des cellules : l'image est découpée en cellules carrées de taille F×F pixels\n",
        "- Le pas S : les cellules sont séparées les unes des autres de S pixels\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Le choix des hyperparamètres se fait selon un schéma classique :\n",
        "- Pour la couche de convolution, les filtres sont de petite taille et glissés sur l'image d'un pixel à la fois. On choisit alors F=3,P=1,S=1 ou F=5,P=2,S=1\n",
        "\n",
        "- Pour la couche de pooling, F=2 et S=2 est un choix judicieux."
      ]
    }
  ]
}